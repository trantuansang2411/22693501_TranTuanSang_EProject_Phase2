# HIá»‚U Há»† THá»NG - KUBERNETES TRÃŠN DOCKER LOCAL

## Má»¥c Lá»¥c
1. [Kind (Kubernetes in Docker) lÃ  gÃ¬?](#1-kind-kubernetes-in-docker-lÃ -gÃ¬)
2. [Kiáº¿n trÃºc há»‡ thá»‘ng](#2-kiáº¿n-trÃºc-há»‡-thá»‘ng)
3. [CÃ¡c thÃ nh pháº§n Kubernetes](#3-cÃ¡c-thÃ nh-pháº§n-kubernetes)
4. [Luá»“ng triá»ƒn khai](#4-luá»“ng-triá»ƒn-khai)
5. [Networking - Máº¡ng trong Kubernetes](#5-networking---máº¡ng-trong-kubernetes)
6. [Storage - LÆ°u trá»¯ dá»¯ liá»‡u](#6-storage---lÆ°u-trá»¯-dá»¯-liá»‡u)
7. [Service Discovery - TÃ¬m kiáº¿m dá»‹ch vá»¥](#7-service-discovery---tÃ¬m-kiáº¿m-dá»‹ch-vá»¥)
8. [ConfigMaps vÃ  Secrets](#8-configmaps-vÃ -secrets)
9. [Health Checks vÃ  Auto-healing](#9-health-checks-vÃ -auto-healing)
10. [Scaling vÃ  Load Balancing](#10-scaling-vÃ -load-balancing)
11. [Luá»“ng hoáº¡t Ä‘á»™ng cá»§a á»©ng dá»¥ng](#11-luá»“ng-hoáº¡t-Ä‘á»™ng-cá»§a-á»©ng-dá»¥ng)
12. [So sÃ¡nh Docker Compose vs Kubernetes](#12-so-sÃ¡nh-docker-compose-vs-kubernetes)

---

## 1. Kind (Kubernetes in Docker) lÃ  gÃ¬?

### KhÃ¡i niá»‡m

**Kind** (Kubernetes IN Docker) lÃ  cÃ´ng cá»¥ cho phÃ©p cháº¡y **Kubernetes cluster bÃªn trong Docker containers**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Desktop (Host)               â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    Kind Cluster                       â”‚ â”‚
â”‚  â”‚                                       â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Container 1  â”‚  â”‚ Container 2  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ Control-Planeâ”‚  â”‚   Worker     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚   (Node)     â”‚  â”‚   (Node)     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â”‚  Pods    â”‚ â”‚  â”‚ â”‚  Pods    â”‚ â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Táº¡i sao dÃ¹ng Kind?

1. **MÃ´i trÆ°á»ng giá»‘ng Production**: Kubernetes tháº­t, khÃ´ng pháº£i giáº£ láº­p
2. **Dá»… dÃ ng**: Cháº¡y trÃªn Docker Desktop, khÃ´ng cáº§n cÃ i Ä‘áº·t phá»©c táº¡p
3. **Isolated**: Má»—i cluster Ä‘á»™c láº­p, khÃ´ng áº£nh hÆ°á»Ÿng há»‡ thá»‘ng
4. **Há»c táº­p & Testing**: HoÃ n háº£o Ä‘á»ƒ há»c Kubernetes vÃ  test

### Kind vs Minikube vs Docker Desktop Kubernetes

| TÃ­nh nÄƒng | Kind | Minikube | Docker Desktop K8s |
|-----------|------|----------|-------------------|
| Cháº¡y trÃªn | Docker containers | VM hoáº·c Docker | Built-in |
| Multi-node | âœ… Dá»… dÃ ng | âš ï¸ Phá»©c táº¡p | âŒ Single node |
| Tá»‘c Ä‘á»™ | âš¡ Nhanh | ğŸ¢ Cháº­m hÆ¡n | âš¡ Nhanh |
| TÃ i nguyÃªn | ğŸ’¾ Nháº¹ | ğŸ’¾ Náº·ng | ğŸ’¾ Nháº¹ |
| Production-like | âœ… Cao | âœ… Cao | âš ï¸ Tháº¥p |

---

## 2. Kiáº¿n TrÃºc Há»‡ Thá»‘ng

### Tá»•ng Quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KUBERNETES CLUSTER                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              CONTROL PLANE NODE                        â”‚    â”‚
â”‚  â”‚  - API Server (Ä‘iá»u phá»‘i cluster)                      â”‚    â”‚
â”‚  â”‚  - Scheduler (lÃªn lá»‹ch pods)                           â”‚    â”‚
â”‚  â”‚  - Controller Manager (quáº£n lÃ½ state)                  â”‚    â”‚
â”‚  â”‚  - etcd (database lÆ°u cluster state)                   â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  + API Gateway Pod (exposed qua port 3003)             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                  WORKER NODE                           â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚ Auth Pods   â”‚  â”‚Product Pods â”‚  â”‚ Order Pods  â”‚    â”‚    â”‚
â”‚  â”‚  â”‚ (x2 replicasâ”‚  â”‚(x2 replicas)â”‚  â”‚(x2 replicas)â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚    â”‚
â”‚  â”‚  â”‚ MongoDB Pod â”‚  â”‚RabbitMQ Pod â”‚                      â”‚    â”‚
â”‚  â”‚  â”‚ + Storage   â”‚  â”‚ + Storage   â”‚                      â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚              â”‚
         â–¼              â–¼              â–¼              â–¼
    Port 3003      Port 3000      Port 3001      Port 27017
   (Gateway)       (Auth)         (Product)      (MongoDB)
```

### CÃ¡c Layer

1. **Infrastructure Layer**: Docker Desktop
2. **Cluster Layer**: Kind cluster vá»›i 2 nodes
3. **Kubernetes Layer**: API Server, Scheduler, Controllers
4. **Application Layer**: Pods cháº¡y microservices
5. **Networking Layer**: Services, DNS, Load Balancing
6. **Storage Layer**: PersistentVolumes

---

## 3. CÃ¡c ThÃ nh Pháº§n Kubernetes

### 3.1. Nodes (MÃ¡y chá»§)

**Node** lÃ  má»™t mÃ¡y (váº­t lÃ½ hoáº·c áº£o) trong cluster. Trong Kind, má»—i node lÃ  má»™t Docker container.

```yaml
# kind-config.yaml
nodes:
  - role: control-plane  # Node master, quáº£n lÃ½ cluster
  - role: worker         # Node worker, cháº¡y workload
```

**Control Plane Node** cháº¡y:
- API Server: Nháº­n requests tá»« kubectl
- Scheduler: Quyáº¿t Ä‘á»‹nh pod cháº¡y trÃªn node nÃ o
- Controller Manager: Äáº£m báº£o desired state = actual state
- etcd: Database lÆ°u trá»¯ toÃ n bá»™ state

**Worker Node** cháº¡y:
- kubelet: Agent quáº£n lÃ½ pods
- kube-proxy: Quáº£n lÃ½ networking
- Container runtime: Docker/containerd cháº¡y containers
- Pods: á»¨ng dá»¥ng thá»±c táº¿

### 3.2. Pods

**Pod** lÃ  Ä‘Æ¡n vá»‹ nhá» nháº¥t trong Kubernetes, chá»©a 1 hoáº·c nhiá»u containers.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Auth Pod           â”‚
â”‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  auth-service    â”‚   â”‚ <- Container cháº¡y Node.js app
â”‚  â”‚  Image: auth:v1  â”‚   â”‚
â”‚  â”‚  Port: 3000      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚
â”‚  Resources:             â”‚
â”‚  - CPU: 100m-200m       â”‚
â”‚  - RAM: 256Mi-512Mi     â”‚
â”‚                         â”‚
â”‚  Environment:           â”‚
â”‚  - PORT=3000            â”‚
â”‚  - JWT_SECRET=xxx       â”‚
â”‚  - MONGODB_URI=xxx      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Táº¡i sao cáº§n Pods?**
- ÄÃ³ng gÃ³i container + config + resources
- CÃ³ IP riÃªng trong cluster
- CÃ³ thá»ƒ restart tá»± Ä‘á»™ng khi lá»—i
- Share network namespace (náº¿u nhiá»u containers)

### 3.3. Deployments

**Deployment** quáº£n lÃ½ viá»‡c táº¡o vÃ  update Pods.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
spec:
  replicas: 2  # Táº¡o 2 pods giá»‘ng há»‡t nhau
  selector:
    matchLabels:
      app: auth-service
  template:    # Template Ä‘á»ƒ táº¡o pods
    spec:
      containers:
      - name: auth-service
        image: auth-service:latest
        ports:
        - containerPort: 3000
```

**Deployment lÃ m gÃ¬?**
1. **Táº¡o ReplicaSet**: Äáº£m báº£o luÃ´n cÃ³ Ä‘Ãºng sá»‘ replicas
2. **Rolling Updates**: Update tá»«ng pod má»™t, khÃ´ng downtime
3. **Rollback**: Quay láº¡i version cÅ© náº¿u cÃ³ lá»—i
4. **Self-healing**: Tá»± táº¡o pod má»›i náº¿u pod cháº¿t

```
Deployment "auth-service"
    â”‚
    â”œâ”€â”€ ReplicaSet (quáº£n lÃ½ 2 replicas)
    â”‚       â”‚
    â”‚       â”œâ”€â”€ Pod 1 (auth-service-abc123)
    â”‚       â””â”€â”€ Pod 2 (auth-service-def456)
```

**VÃ­ dá»¥ thá»±c táº¿:**
```bash
# Ban Ä‘áº§u: 2 pods running
Pod: auth-service-abc123  [Running]
Pod: auth-service-def456  [Running]

# Pod 1 bá»‹ crash
Pod: auth-service-abc123  [Crashed] âŒ

# Deployment tá»± Ä‘á»™ng táº¡o pod má»›i
Pod: auth-service-xyz789  [Starting...]
Pod: auth-service-def456  [Running]

# Sau vÃ i giÃ¢y
Pod: auth-service-xyz789  [Running] âœ…
Pod: auth-service-def456  [Running] âœ…
```

### 3.4. Services

**Service** lÃ  "Ä‘á»‹a chá»‰ cá»‘ Ä‘á»‹nh" Ä‘á»ƒ truy cáº­p Pods (vÃ¬ Pods cÃ³ thá»ƒ thay Ä‘á»•i IP khi restart).

```
Service "auth-service" (ClusterIP: 10.96.1.5)
    â”‚
    â”œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€ Load Balancer
    â”‚     â”‚
    â–¼     â–¼
Pod 1   Pod 2
(IP: 10.244.1.5) (IP: 10.244.2.3)
```

**CÃ¡c loáº¡i Service:**

1. **ClusterIP** (default): Chá»‰ truy cáº­p Ä‘Æ°á»£c tá»« trong cluster
   ```yaml
   type: ClusterIP
   # DÃ¹ng cho: MongoDB, RabbitMQ (khÃ´ng cáº§n expose ra ngoÃ i)
   ```

2. **NodePort**: Expose ra ngoÃ i qua port trÃªn Node
   ```yaml
   type: NodePort
   ports:
   - port: 3000        # Port trong cluster
     targetPort: 3000  # Port cá»§a container
     nodePort: 30000   # Port trÃªn host (30000-32767)
   # Truy cáº­p: localhost:30000
   ```

3. **LoadBalancer**: Táº¡o external load balancer (cloud only)
   
4. **ExternalName**: Map tÃªn DNS

**VÃ­ dá»¥:**
```yaml
# Service cho Auth
apiVersion: v1
kind: Service
metadata:
  name: auth-service
spec:
  type: NodePort
  selector:
    app: auth-service  # Chá»n pods cÃ³ label nÃ y
  ports:
  - port: 3000         # Port service trong cluster
    targetPort: 3000   # Port container
    nodePort: 30000    # Port expose ra ngoÃ i
```

**Service lÃ m gÃ¬?**
- Cung cáº¥p DNS name: `auth-service.default.svc.cluster.local`
- Load balancing giá»¯a cÃ¡c pods
- Health checking: Chá»‰ route Ä‘áº¿n healthy pods
- Port mapping

### 3.5. ConfigMaps

**ConfigMap** lÆ°u trá»¯ configuration khÃ´ng nháº¡y cáº£m.

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  AUTH_PORT: "3000"
  PRODUCT_PORT: "3001"
  ORDER_SERVICE_URL: "http://order-service:3002"
```

**Sá»­ dá»¥ng trong Pod:**
```yaml
env:
- name: PORT
  valueFrom:
    configMapKeyRef:
      name: app-config
      key: AUTH_PORT
```

**Táº¡i sao cáº§n ConfigMap?**
- âœ… TÃ¡ch config ra khá»i code
- âœ… Thay Ä‘á»•i config khÃ´ng cáº§n rebuild image
- âœ… Share config giá»¯a nhiá»u pods
- âœ… Dá»… quáº£n lÃ½ mÃ´i trÆ°á»ng (dev, staging, prod)

### 3.6. Secrets

**Secret** lÆ°u trá»¯ thÃ´ng tin nháº¡y cáº£m (passwords, tokens, keys).

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
stringData:
  jwt-secret: "your_jwt_secret_key_here"
  mongodb-uri: "mongodb://mongodb:27017/auth"
```

**KhÃ¡c vá»›i ConfigMap:**
- âœ… ÄÆ°á»£c encode base64
- âœ… CÃ³ thá»ƒ encrypt at rest
- âœ… Access control cháº·t cháº½ hÆ¡n
- âœ… KhÃ´ng hiá»ƒn thá»‹ trong logs

### 3.7. PersistentVolumes (PV) vÃ  PersistentVolumeClaims (PVC)

**Váº¥n Ä‘á»:** Khi Pod restart, data trong container bá»‹ máº¥t.

**Giáº£i phÃ¡p:** PersistentVolume - storage tá»“n táº¡i Ä‘á»™c láº­p vá»›i Pod lifecycle.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    PersistentVolume (PV)         â”‚
â”‚    - Capacity: 5Gi               â”‚
â”‚    - Path: /mnt/data/mongodb     â”‚
â”‚    - StorageClass: manual        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–²
              â”‚ Bound (liÃªn káº¿t)
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PersistentVolumeClaim (PVC)     â”‚
â”‚  - Request: 5Gi                  â”‚
â”‚  - AccessMode: ReadWriteOnce     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–²
              â”‚ Mount
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MongoDB Pod              â”‚
â”‚  volumeMounts:                   â”‚
â”‚    - mountPath: /data/db         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Luá»“ng hoáº¡t Ä‘á»™ng:**
1. Admin táº¡o **PV**: "TÃ´i cÃ³ 5GB storage táº¡i path nÃ y"
2. User táº¡o **PVC**: "TÃ´i cáº§n 5GB storage"
3. Kubernetes **bind** PVC vá»›i PV phÃ¹ há»£p
4. Pod **mount** PVC vÃ o container

**VÃ­ dá»¥ thá»±c táº¿:**
```yaml
# 1. PersistentVolume
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mongodb-pv
spec:
  capacity:
    storage: 5Gi
  hostPath:
    path: "/mnt/data/mongodb"  # ÄÆ°á»ng dáº«n trÃªn node

# 2. PersistentVolumeClaim
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc
spec:
  resources:
    requests:
      storage: 5Gi

# 3. Sá»­ dá»¥ng trong Pod
spec:
  volumes:
  - name: mongodb-storage
    persistentVolumeClaim:
      claimName: mongodb-pvc
  containers:
  - name: mongodb
    volumeMounts:
    - name: mongodb-storage
      mountPath: /data/db  # MongoDB lÆ°u data á»Ÿ Ä‘Ã¢y
```

**Káº¿t quáº£:**
- âœ… MongoDB data Ä‘Æ°á»£c lÆ°u táº¡i `/mnt/data/mongodb` trÃªn node
- âœ… Pod restart â†’ data váº«n cÃ²n
- âœ… Delete pod â†’ data váº«n cÃ²n
- âœ… Chá»‰ máº¥t data khi delete PV

---

## 4. Luá»“ng Triá»ƒn Khai

### BÆ°á»›c 1: Build Docker Images

```bash
docker build -t auth-service:latest ./auth
```

**Äiá»u gÃ¬ xáº£y ra?**
1. Docker Ä‘á»c Dockerfile
2. Pull base image (`node:18-alpine`)
3. Copy code vÃ o image
4. Install dependencies
5. Táº¡o image vá»›i tag `auth-service:latest`
6. LÆ°u image vÃ o Docker local registry

### BÆ°á»›c 2: Táº¡o Kind Cluster

```bash
kind create cluster --config=kind-config.yaml --name eproject-cluster
```

**Äiá»u gÃ¬ xáº£y ra?**

```
1. Kind Ä‘á»c config file
   â†“
2. Táº¡o Docker network "kind"
   â†“
3. Pull Kind node image (kindest/node:v1.27.3)
   â†“
4. Táº¡o container cho Control Plane node
   - Cháº¡y kubeadm init
   - Start API Server, Scheduler, Controller Manager, etcd
   - Cáº¥u hÃ¬nh networking (CNI)
   â†“
5. Táº¡o container cho Worker node
   - Join cluster báº±ng token
   - Start kubelet, kube-proxy
   â†“
6. Setup port mappings (3000â†’30000, 3001â†’30001, etc.)
   â†“
7. Generate kubeconfig file
   â†“
8. Cluster sáºµn sÃ ng!
```

**Kiá»ƒm tra:**
```bash
docker ps
# Sáº½ tháº¥y 2 containers:
# - eproject-cluster-control-plane
# - eproject-cluster-worker

kubectl get nodes
# Sáº½ tháº¥y 2 nodes á»Ÿ tráº¡ng thÃ¡i Ready
```

### BÆ°á»›c 3: Load Images vÃ o Cluster

```bash
kind load docker-image auth-service:latest --name eproject-cluster
```

**Táº¡i sao cáº§n bÆ°á»›c nÃ y?**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Desktop                      â”‚
â”‚                                             â”‚
â”‚  Docker Images:                             â”‚
â”‚  - auth-service:latest       âœ… CÃ³         â”‚
â”‚  - product-service:latest    âœ… CÃ³         â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ Kind cluster KHÃ”NG tá»± Ä‘á»™ng
                    â”‚ truy cáº­p Ä‘Æ°á»£c images nÃ y!
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Kind Cluster                           â”‚
â”‚  (containers riÃªng biá»‡t)                    â”‚
â”‚                                             â”‚
â”‚  Images trong cluster:                      â”‚
â”‚  - auth-service:latest       âŒ ChÆ°a cÃ³    â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**kind load lÃ m gÃ¬?**
1. Tar image tá»« Docker local
2. Copy tar file vÃ o Kind node containers
3. Import image vÃ o container runtime cá»§a nodes
4. Giá» pods cÃ³ thá»ƒ pull image tá»« local

**Sau khi load:**
```bash
docker exec -it eproject-cluster-control-plane crictl images
# Sáº½ tháº¥y auth-service:latest trong danh sÃ¡ch
```

### BÆ°á»›c 4: Deploy ConfigMaps & Secrets

```bash
kubectl apply -f k8s/configmap-secret.yaml
```

**Äiá»u gÃ¬ xáº£y ra?**

```
1. kubectl gá»­i YAML Ä‘áº¿n API Server
   â†“
2. API Server validate YAML
   â†“
3. LÆ°u vÃ o etcd database
   â†“
4. ConfigMap & Secret Ä‘Æ°á»£c táº¡o
   â†“
5. Pods cÃ³ thá»ƒ reference chÃºng
```

### BÆ°á»›c 5: Deploy MongoDB

```bash
kubectl apply -f k8s/mongodb.yaml
```

**Äiá»u gÃ¬ xáº£y ra?**

```
1. kubectl apply â†’ API Server
   â†“
2. API Server táº¡o PV, PVC, Deployment, Service
   â†“
3. Scheduler chá»n node Ä‘á»ƒ cháº¡y MongoDB pod
   - Kiá»ƒm tra resources available
   - Chá»n worker node
   â†“
4. kubelet trÃªn worker node:
   - Pull image mongo:6.0 (náº¿u chÆ°a cÃ³)
   - Táº¡o vÃ  mount PersistentVolume
   - Start container
   - Inject environment variables
   â†“
5. Container start:
   - MongoDB khá»Ÿi Ä‘á»™ng
   - Láº¯ng nghe port 27017
   â†“
6. Health checks:
   - kubelet kiá»ƒm tra container health
   - Pod status: Running
   â†“
7. Service Ä‘Æ°á»£c táº¡o:
   - DNS entry: mongodb.default.svc.cluster.local
   - ClusterIP assigned
   - Endpoints updated
   â†“
8. MongoDB sáºµn sÃ ng nháº­n connections!
```

### BÆ°á»›c 6: Deploy Microservices

```bash
kubectl apply -f k8s/auth-service.yaml
```

**Äiá»u gÃ¬ xáº£y ra?**

```
1. Deployment "auth-service" Ä‘Æ°á»£c táº¡o
   - Replicas: 2
   â†“
2. ReplicaSet Ä‘Æ°á»£c táº¡o
   â†“
3. Scheduler schedule 2 pods
   - Pod 1 â†’ Control Plane node
   - Pod 2 â†’ Worker node
   (hoáº·c cáº£ 2 trÃªn Worker, tÃ¹y thuá»™c vÃ o resources)
   â†“
4. kubelet trÃªn má»—i node:
   - Pull image auth-service:latest (tá»« local)
   - Táº¡o container vá»›i env vars tá»« ConfigMap/Secret
   - Start container
   â†“
5. Container start:
   - Node.js app khá»Ÿi Ä‘á»™ng
   - Káº¿t ná»‘i MongoDB (qua service name "mongodb")
   - Listen port 3000
   â†“
6. Health checks báº¯t Ä‘áº§u:
   - Readiness probe: GET /health
   - Liveness probe: GET /health
   â†“
7. Khi probe thÃ nh cÃ´ng:
   - Pod status: Ready
   - Service endpoints updated
   - Traffic cÃ³ thá»ƒ route Ä‘áº¿n pod
   â†“
8. Service "auth-service" active
   - 2 pods healthy
   - Load balancing enabled
   - Accessible táº¡i: http://auth-service:3000
                     http://localhost:30000
```

---

## 5. Networking - Máº¡ng trong Kubernetes

### 5.1. Cluster Networking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Kind Cluster                  â”‚
â”‚         Network: 10.244.0.0/16 (Pod CIDR)      â”‚
â”‚         Services: 10.96.0.0/12 (Service CIDR)  â”‚
â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Control Plane Node (10.244.0.0/24)     â”‚ â”‚
â”‚  â”‚    Pod: api-gateway (10.244.0.5)        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Worker Node (10.244.1.0/24)            â”‚ â”‚
â”‚  â”‚    Pod: auth-1 (10.244.1.5)             â”‚ â”‚
â”‚  â”‚    Pod: auth-2 (10.244.1.6)             â”‚ â”‚
â”‚  â”‚    Pod: product-1 (10.244.1.7)          â”‚ â”‚
â”‚  â”‚    Pod: mongodb (10.244.1.8)            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚
â”‚  Services:                                     â”‚
â”‚    - auth-service: 10.96.1.5:3000            â”‚
â”‚    - mongodb: 10.96.2.10:27017               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚ Port Mapping (Kind extraPortMappings)
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Docker Host (localhost)             â”‚
â”‚                                                â”‚
â”‚   localhost:3000  â†’ NodePort 30000 â†’ auth     â”‚
â”‚   localhost:3003  â†’ NodePort 30003 â†’ gateway  â”‚
â”‚   localhost:27017 â†’ NodePort 30017 â†’ mongodb  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2. DNS trong Kubernetes

Kubernetes tá»± Ä‘á»™ng táº¡o DNS records cho Services.

**Format:** `<service-name>.<namespace>.svc.cluster.local`

```
Service: auth-service (namespace: default)
  â”‚
  â”œâ”€â”€ Short name: auth-service
  â”œâ”€â”€ Namespace-qualified: auth-service.default
  â””â”€â”€ FQDN: auth-service.default.svc.cluster.local
```

**VÃ­ dá»¥ trong code:**
```javascript
// Product service káº¿t ná»‘i Ä‘áº¿n Order service
const ORDER_SERVICE_URL = process.env.ORDER_SERVICE_URL;
// Value: "http://order-service:3002"

// Kubernetes DNS resolve:
// order-service â†’ 10.96.3.15 (Service ClusterIP)
```

**Test DNS:**
```bash
kubectl exec -it <pod-name> -- nslookup auth-service
# Output:
# Name: auth-service.default.svc.cluster.local
# Address: 10.96.1.5
```

### 5.3. Service-to-Service Communication

**VÃ­ dá»¥: API Gateway gá»i Auth Service**

```
1. Browser â†’ http://localhost:3003/auth/login
   â†“
2. Request Ä‘áº¿n Kind control-plane container (port mapping)
   â†“
3. NodePort 30003 â†’ Service "api-gateway"
   â†“
4. Service load-balance â†’ API Gateway Pod
   â†“
5. API Gateway nháº­n request:
   - Path: /auth/login
   - Proxy to: AUTH_SERVICE_URL
   â†“
6. API Gateway gá»i: http://auth-service:3000/login
   â†“
7. Kubernetes DNS:
   - Resolve "auth-service" â†’ 10.96.1.5
   â†“
8. Request Ä‘áº¿n Service "auth-service"
   â†“
9. Service load-balance â†’ Auth Pod (1 trong 2 replicas)
   â†“
10. Auth Pod xá»­ lÃ½ login:
    - Káº¿t ná»‘i MongoDB: mongodb:27017
    - DNS resolve: mongodb â†’ 10.96.2.10
    - Query database
    - Generate JWT token
    â†“
11. Response tráº£ vá»:
    Auth Pod â†’ Service â†’ API Gateway Pod â†’ NodePort â†’ Browser
```

### 5.4. External Access

**3 cÃ¡ch truy cáº­p tá»« bÃªn ngoÃ i:**

1. **NodePort** (Ä‘ang dÃ¹ng)
   ```
   localhost:3000 â†’ Node:30000 â†’ Service â†’ Pod
   ```
   - âœ… ÄÆ¡n giáº£n
   - âš ï¸ Port range giá»›i háº¡n (30000-32767)

2. **LoadBalancer** (cloud only)
   ```
   External IP â†’ Cloud LB â†’ Service â†’ Pod
   ```
   - âœ… Production-ready
   - âŒ Cáº§n cloud provider

3. **Ingress** (recommended cho production)
   ```
   example.com/auth â†’ Ingress â†’ Service â†’ Pod
   ```
   - âœ… HTTP/HTTPS routing
   - âœ… SSL termination
   - âœ… Path-based routing

---

## 6. Storage - LÆ°u Trá»¯ Dá»¯ Liá»‡u

### 6.1. Váº¥n Äá» vá»›i Container Storage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MongoDB Pod (v1)                â”‚
â”‚  - Data: /data/db                   â”‚
â”‚  - File: users.bson (100MB)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Pod crashed!
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MongoDB Pod (v2) - NEW          â”‚
â”‚  - Data: /data/db                   â”‚
â”‚  - File: EMPTY âŒ                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Data máº¥t vÃ¬:** Container filesystem lÃ  ephemeral (táº¡m thá»i)

### 6.2. PersistentVolume Solution

```
Host Filesystem (Kind Node)
/mnt/data/mongodb/
  â”œâ”€â”€ users.bson
  â”œâ”€â”€ products.bson
  â””â”€â”€ orders.bson
        â–²
        â”‚ Mount
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PersistentVolume (5Gi)            â”‚
â”‚   - hostPath: /mnt/data/mongodb     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²
        â”‚ Claim
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PersistentVolumeClaim (5Gi)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²
        â”‚ Mount
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MongoDB Pod (ANY version)       â”‚
â”‚  volumeMount: /data/db              â”‚
â”‚  â†’ Points to /mnt/data/mongodb      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Lifecycle:**

```bash
# 1. Táº¡o PV
kubectl apply -f mongodb.yaml
# PV created: /mnt/data/mongodb exists on node

# 2. MongoDB pod starts
# - PVC binds to PV
# - Volume mounted to /data/db
# - MongoDB writes data â†’ /mnt/data/mongodb

# 3. Pod crashes
kubectl delete pod mongodb-xxx
# - Pod deleted
# - PVC still exists
# - PV still exists
# - Data at /mnt/data/mongodb intact

# 4. New pod starts
# - Same PVC
# - Same PV
# - Mount same /mnt/data/mongodb
# - MongoDB sees existing data âœ…
```

### 6.3. Access Modes

```yaml
accessModes:
  - ReadWriteOnce (RWO)  # 1 node, read-write
  - ReadOnlyMany (ROX)   # Nhiá»u nodes, read-only
  - ReadWriteMany (RWX)  # Nhiá»u nodes, read-write
```

**MongoDB/RabbitMQ dÃ¹ng RWO vÃ¬:**
- Chá»‰ 1 pod ghi dá»¯ liá»‡u (stateful)
- TrÃ¡nh race conditions
- Simpler locking

---

## 7. Service Discovery - TÃ¬m Kiáº¿m Dá»‹ch Vá»¥

### 7.1. Váº¥n Äá» Cáº§n Giáº£i Quyáº¿t

```
# Trong Docker Compose:
services:
  auth:
    hostname: auth-service  # Cá»‘ Ä‘á»‹nh
  product:
    environment:
      AUTH_URL: http://auth-service:3000  # Hardcode OK

# Trong Kubernetes:
Pod: auth-service-abc123 (IP: 10.244.1.5)  # IP thay Ä‘á»•i!
Pod: auth-service-def456 (IP: 10.244.1.6)
Pod: auth-service-xyz789 (IP: 10.244.1.7)  # Replicas khÃ¡c nhau

# Product service gá»i Ä‘á»‹a chá»‰ nÃ o? ğŸ¤”
```

### 7.2. Solution: Kubernetes Services

```yaml
apiVersion: v1
kind: Service
metadata:
  name: auth-service  # TÃªn cá»‘ Ä‘á»‹nh, DNS entry
spec:
  selector:
    app: auth-service  # Chá»n táº¥t cáº£ pods cÃ³ label nÃ y
  ports:
  - port: 3000
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**

```
1. Product service cáº§n gá»i Auth
   â†“
2. Code: http://auth-service:3000/login
   â†“
3. DNS lookup: auth-service
   â†“
4. CoreDNS (Kubernetes DNS):
   - TÃ¬m Service tÃªn "auth-service"
   - Return ClusterIP: 10.96.1.5
   â†“
5. Request Ä‘áº¿n 10.96.1.5:3000
   â†“
6. kube-proxy (trÃªn má»—i node):
   - Intercept request
   - Load-balance Ä‘áº¿n 1 trong cÃ¡c pod IPs:
     * 10.244.1.5 (auth-pod-1)
     * 10.244.1.6 (auth-pod-2)
   â†“
7. Request delivered Ä‘áº¿n pod Ä‘Æ°á»£c chá»n
```

### 7.3. Endpoints

**Endpoints** = Danh sÃ¡ch IP:Port cá»§a pods behind service

```bash
kubectl get endpoints auth-service

# Output:
NAME           ENDPOINTS
auth-service   10.244.1.5:3000,10.244.1.6:3000
```

**Update tá»± Ä‘á»™ng:**
```
# Initial state
Endpoints: 10.244.1.5:3000, 10.244.1.6:3000

# Pod 2 crashes
â†“
# Endpoint controller removes unhealthy pod
Endpoints: 10.244.1.5:3000

# New pod starts
â†“
# Readiness probe passes
â†“
# Endpoint added
Endpoints: 10.244.1.5:3000, 10.244.1.7:3000
```

---

## 8. ConfigMaps vÃ  Secrets

### 8.1. Táº¡i Sao Cáº§n?

**Váº¥n Ä‘á» vá»›i hardcode:**

```javascript
// âŒ BAD: Hardcode trong code
const MONGODB_URI = "mongodb://mongodb:27017/auth";
const JWT_SECRET = "my-super-secret-key";

// Váº¥n Ä‘á»:
// 1. Thay Ä‘á»•i config â†’ pháº£i rebuild image
// 2. Secret lá»™ trong source code
// 3. KhÃ¡c nhau giá»¯a dev/prod â†’ pháº£i maintain nhiá»u images
```

**Giáº£i phÃ¡p:**

```javascript
// âœ… GOOD: Äá»c tá»« environment variables
const MONGODB_URI = process.env.MONGODB_AUTH_URI;
const JWT_SECRET = process.env.JWT_SECRET;

// Config inject tá»« Kubernetes ConfigMap/Secret
```

### 8.2. ConfigMap cho Non-Sensitive Data

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  AUTH_PORT: "3000"
  PRODUCT_PORT: "3001"
  ORDER_SERVICE_URL: "http://order-service:3002"
```

**Sá»­ dá»¥ng:**
```yaml
spec:
  containers:
  - name: auth
    env:
    - name: PORT
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: AUTH_PORT
```

**Trong container:**
```bash
echo $PORT
# Output: 3000
```

### 8.3. Secret cho Sensitive Data

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
stringData:
  jwt-secret: "your_jwt_secret_key_here"
  mongodb-uri: "mongodb://mongodb:27017/auth"
```

**KhÃ¡c biá»‡t:**
- ConfigMap: Plain text, visible
- Secret: Base64 encoded, cÃ³ thá»ƒ encrypt

**Security best practices:**
```bash
# âŒ KhÃ´ng commit secrets vÃ o Git
git add k8s/secret.yaml  # BAD

# âœ… DÃ¹ng sealed-secrets hoáº·c external secret management
# âœ… Hoáº·c táº¡o secrets báº±ng kubectl:
kubectl create secret generic app-secrets \
  --from-literal=jwt-secret=xxx \
  --from-literal=mongodb-uri=xxx
```

### 8.4. Update Config Without Downtime

```bash
# 1. Update ConfigMap
kubectl edit configmap app-config
# Change: AUTH_PORT: "3000" â†’ "8080"

# 2. Restart deployment
kubectl rollout restart deployment auth-service

# Rolling update:
# - Pod 1 (old): Running
# - Pod 3 (new): Starting with new config
# - Pod 3: Ready
# - Pod 1: Terminating
# - Pod 2 (old): Running
# - Pod 4 (new): Starting
# - Pod 4: Ready
# - Pod 2: Terminating
# âœ… No downtime!
```

---

## 9. Health Checks vÃ  Auto-healing

### 9.1. Liveness Probe

**Má»¥c Ä‘Ã­ch:** PhÃ¡t hiá»‡n pod "zombie" (cháº¡y nhÆ°ng khÃ´ng hoáº¡t Ä‘á»™ng)

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 3000
  initialDelaySeconds: 30  # Äá»£i 30s sau khi start
  periodSeconds: 10         # Check má»—i 10s
  failureThreshold: 3       # Fail 3 láº§n â†’ restart
```

**Ká»‹ch báº£n:**

```
1. Pod starts â†’ Auth service starting...
   â†“ (30 seconds delay)
2. First liveness check: GET /health
   â†“
3. Response 200 OK â†’ Pod healthy âœ…
   â†“ (10 seconds)
4. Second check: GET /health
   â†“
5. Response 200 OK â†’ Pod healthy âœ…
   â†“
   ... time passes ...
   â†“
6. App bug â†’ Deadlock â†’ Cannot respond
   â†“
7. Liveness check: GET /health
   â†“ (timeout)
8. No response â†’ Failure count: 1
   â†“ (10 seconds)
9. Check again â†’ No response â†’ Failure count: 2
   â†“ (10 seconds)
10. Check again â†’ No response â†’ Failure count: 3
    â†“
11. Threshold reached â†’ Kill container
    â†“
12. kubelet restarts container
    â†“
13. Fresh start â†’ App healthy again âœ…
```

### 9.2. Readiness Probe

**Má»¥c Ä‘Ã­ch:** PhÃ¡t hiá»‡n pod chÆ°a sáºµn sÃ ng nháº­n traffic

```yaml
readinessProbe:
  httpGet:
    path: /health
    port: 3000
  initialDelaySeconds: 10
  periodSeconds: 5
  failureThreshold: 3
```

**KhÃ¡c vá»›i Liveness:**
- Liveness fail â†’ **Restart container**
- Readiness fail â†’ **Remove from service endpoints** (khÃ´ng restart)

**Ká»‹ch báº£n:**

```
1. Pod starts
   â†“
2. Container running but:
   - MongoDB connection pending
   - Loading large dataset
   - Warming up cache
   â†“
3. Readiness probe: GET /health
   â†“
4. Response 503 Service Unavailable
   â†“
5. Pod status: Running but NOT Ready
   â†“
6. Service endpoints: Pod NOT included
   - No traffic routed to this pod
   â†“
7. App initialization completes
   - MongoDB connected
   - Ready to serve requests
   â†“
8. Readiness probe: GET /health
   â†“
9. Response 200 OK
   â†“
10. Pod status: Running and Ready âœ…
    â†“
11. Service endpoints: Pod included
    â†“
12. Traffic starts flowing to pod
```

### 9.3. Health Endpoint Implementation

```javascript
// auth/src/app.js
setRoutes() {
  // Health check endpoint
  this.app.get("/health", (req, res) => {
    // Check dependencies
    const mongoStatus = mongoose.connection.readyState === 1 
      ? 'connected' 
      : 'disconnected';
    
    if (mongoStatus === 'connected') {
      res.status(200).json({
        status: "ok",
        service: "auth",
        timestamp: new Date().toISOString(),
        mongodb: mongoStatus
      });
    } else {
      res.status(503).json({
        status: "error",
        service: "auth",
        mongodb: mongoStatus
      });
    }
  });
}
```

**Best practices:**
- âœ… Check critical dependencies (DB, cache, etc.)
- âœ… Fast response (< 1s)
- âœ… Don't do heavy computation
- âœ… Return proper HTTP codes (200, 503)

---

## 10. Scaling vÃ  Load Balancing

### 10.1. Horizontal Scaling

**VÃ­ dá»¥: Auth service cÃ³ 2 replicas**

```yaml
spec:
  replicas: 2
```

**Táº¡i sao cáº§n nhiá»u replicas?**

1. **High Availability**: 1 pod crash â†’ cÃ²n pod khÃ¡c
2. **Load Distribution**: Chia traffic
3. **Rolling Updates**: Update khÃ´ng downtime

### 10.2. Load Balancing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Service "auth-service"            â”‚
â”‚      ClusterIP: 10.96.1.5              â”‚
â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚    kube-proxy (iptables)   â”‚      â”‚
â”‚   â”‚    Load Balancing Algorithmâ”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€ Round Robin â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                           â”‚
            â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Auth Pod 1  â”‚          â”‚  Auth Pod 2  â”‚
    â”‚ 10.244.1.5   â”‚          â”‚ 10.244.1.6   â”‚
    â”‚ CPU: 40%     â”‚          â”‚ CPU: 35%     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Traffic distribution:**
```
Request 1 â†’ Pod 1
Request 2 â†’ Pod 2
Request 3 â†’ Pod 1
Request 4 â†’ Pod 2
...
```

### 10.3. Manual Scaling

```bash
# Scale up
kubectl scale deployment auth-service --replicas=5

# Kubernetes will:
# 1. Create 3 new pods
# 2. Schedule them on available nodes
# 3. Add to service endpoints when ready
# 4. Start receiving traffic

# Scale down
kubectl scale deployment auth-service --replicas=2

# Kubernetes will:
# 1. Choose 3 pods to terminate
# 2. Remove from service endpoints
# 3. Gracefully shutdown pods
# 4. Delete pods
```

### 10.4. Auto-scaling (HPA - Horizontal Pod Autoscaler)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: auth-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: auth-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # Target 70% CPU
```

**CÃ¡ch hoáº¡t Ä‘á»™ng:**
```
1. Metrics server thu tháº­p CPU usage
   â†“
2. Current: 2 pods, Average CPU: 85%
   â†“
3. HPA: 85% > 70% target â†’ Need more pods
   â†“
4. Calculate: (85 / 70) Ã— 2 = 2.4 â†’ Round up = 3 pods
   â†“
5. Scale up: 2 â†’ 3 pods
   â†“
6. Traffic distributes across 3 pods
   â†“
7. Average CPU drops to 60%
   â†“
8. HPA: 60% < 70% â†’ Good âœ…
```

---

## 11. Luá»“ng Hoáº¡t Äá»™ng cá»§a á»¨ng Dá»¥ng

### 11.1. User Registration Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Browser â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â”‚ POST /auth/register
     â”‚ Body: {username, password, email}
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   localhost:3003                     â”‚ 1. Request Ä‘áº¿n host
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Port mapping (Kind)
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NodePort 30003                     â”‚ 2. Forward to NodePort
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Service routing
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Service: api-gateway               â”‚ 3. Service load-balance
â”‚   ClusterIP: 10.96.4.10              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Select pod (round-robin)
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pod: api-gateway-abc123            â”‚ 4. Pod nháº­n request
â”‚   IP: 10.244.0.5                     â”‚    Path: /auth/register
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Proxy request
     â”‚ To: http://auth-service:3000/register
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DNS Resolution                     â”‚ 5. Resolve service name
â”‚   auth-service â†’ 10.96.1.5           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Service: auth-service              â”‚ 6. Auth service
â”‚   ClusterIP: 10.96.1.5               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Load-balance to pod
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pod: auth-service-def456           â”‚ 7. Auth pod processes
â”‚   IP: 10.244.1.6                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Need to save user
     â”‚ Connect: mongodb:27017
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DNS: mongodb â†’ 10.96.2.10          â”‚ 8. Resolve MongoDB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Service: mongodb                   â”‚ 9. MongoDB service
â”‚   ClusterIP: 10.96.2.10              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pod: mongodb-xyz789                â”‚ 10. MongoDB pod
â”‚   IP: 10.244.1.8                     â”‚     Saves user data
â”‚   PV: /mnt/data/mongodb              â”‚     to PersistentVolume
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Data saved âœ…
     â–¼
Response flows back:
MongoDB â†’ Auth Pod â†’ API Gateway â†’ Browser
```

### 11.2. Create Order Flow (vá»›i RabbitMQ)

```
1. User places order (via API Gateway)
   â†“
2. Request â†’ Product Service
   â†“
3. Product Service:
   - Validates product exists
   - Creates order message
   - Publishes to RabbitMQ queue "orders"
   â†“
4. RabbitMQ:
   - Message stored in queue
   - Persistent (survives restart)
   â†“
5. Order Service (consumer):
   - Listens to queue "orders"
   - Receives message
   - Processes order
   - Saves to MongoDB
   â†“
6. Asynchronous processing complete âœ…
```

**Táº¡i sao dÃ¹ng RabbitMQ?**
- âœ… Decoupling: Product khÃ´ng cáº§n wait Order service
- âœ… Reliability: Message khÃ´ng máº¥t náº¿u Order service down
- âœ… Scalability: Nhiá»u Order consumers xá»­ lÃ½ parallel

---

## 12. So SÃ¡nh Docker Compose vs Kubernetes

### Docker Compose

```yaml
services:
  auth:
    build: ./auth
    ports:
      - "3000:3000"
    environment:
      - MONGODB_URI=mongodb://mongo:27017
```

**Äáº·c Ä‘iá»ƒm:**
- âœ… ÄÆ¡n giáº£n, dá»… setup
- âœ… Tá»‘t cho development
- âŒ Single host only
- âŒ KhÃ´ng cÃ³ auto-healing
- âŒ KhÃ´ng cÃ³ load balancing
- âŒ KhÃ³ scale

### Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
spec:
  replicas: 2  # Multiple instances
  template:
    spec:
      containers:
      - name: auth
        image: auth-service:latest
```

**Äáº·c Ä‘iá»ƒm:**
- âœ… Multi-host clustering
- âœ… Auto-healing (restart failed pods)
- âœ… Built-in load balancing
- âœ… Easy scaling
- âœ… Rolling updates
- âœ… Health checks
- âœ… Service discovery
- âš ï¸ Phá»©c táº¡p hÆ¡n
- âš ï¸ Learning curve cao

### Khi NÃ o DÃ¹ng GÃ¬?

**Docker Compose:**
- Local development
- Simple applications
- Single server deployment
- Quick prototyping

**Kubernetes:**
- Production environments
- Microservices architecture
- Need high availability
- Need auto-scaling
- Multi-server deployment
- CI/CD pipelines

---

## Tá»•ng Káº¿t

### CÃ¡c KhÃ¡i Niá»‡m ChÃ­nh

1. **Kind**: Kubernetes cluster cháº¡y trong Docker containers
2. **Nodes**: MÃ¡y chá»§ trong cluster (control-plane + workers)
3. **Pods**: ÄÆ¡n vá»‹ nhá» nháº¥t, chá»©a containers
4. **Deployments**: Quáº£n lÃ½ pods, replicas, updates
5. **Services**: Networking, DNS, load balancing
6. **ConfigMaps/Secrets**: Configuration management
7. **PersistentVolumes**: Data persistence
8. **Health Checks**: Liveness & readiness probes

### Luá»“ng Hoáº¡t Äá»™ng Tá»•ng QuÃ¡t

```
Build Images â†’ Create Cluster â†’ Load Images â†’ 
Deploy Infrastructure â†’ Deploy Services â†’ 
Health Checks Pass â†’ Services Ready â†’ 
Handle Requests
```

### Lá»£i Ãch cá»§a Kubernetes

1. **Reliability**: Auto-healing, self-recovery
2. **Scalability**: Easy horizontal scaling
3. **Availability**: Multiple replicas, zero downtime updates
4. **Portability**: Run anywhere (local, cloud, on-premise)
5. **Service Discovery**: Automatic DNS, networking
6. **Configuration**: Separate config from code
7. **Storage**: Persistent data management

### Best Practices

1. âœ… LuÃ´n define health checks
2. âœ… Set resource limits
3. âœ… Use ConfigMaps/Secrets
4. âœ… Enable auto-scaling cho production
5. âœ… Use PersistentVolumes cho stateful apps
6. âœ… Multiple replicas cho high availability
7. âœ… Implement proper logging
8. âœ… Monitor metrics

---

**ChÃºc báº¡n há»c tá»‘t Kubernetes! ğŸš€**
